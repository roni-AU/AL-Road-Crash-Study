{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Alabama Crash Data 2018 – Data Quality and Cleaning\n",
    "\n",
    "This notebook covers **Task - 1: Data Quality and Cleaning**. We load, tidy, and assess data quality for the 2018 Alabama crash dataset (22 selected variables).\n",
    "\n",
    "## Goals:\n",
    "- Verify that each row represents a single crash event.\n",
    "- Ensure variables have appropriate data types.\n",
    "- Treatment missing and unknown values.\n",
    "- Transformation of multiple categorical options to fewer standard outcomes\n",
    "- Create a crash‐severity variable that will be used in later EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 2.1. Setup and loading the dataset\n",
    "The original dataset contained 160,163 crash records with 235 columns. Many of these columns included administrative information or repeated data. To keep the scope of the present study focused, we selected only the variables related to crash severity, crash occurrence, roadway characteristics, environmental conditions, driver demographics, and DUI-related factors. In total, 22 relevant variables were chosen. A separate CSV file containing these 22 columns was created and loaded for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/raw/Raw_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2.1.1. Initial structure\n",
    "\n",
    "We start by confirming the basic structure of the dataset and verifying that each row corresponds to one crash event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1.2. Description of selected variables\n",
    "Our 22 variables capture crash outcomes, roadway environment, traffic characteristics, and key driver factors. The injury count variables (`Number Killed`, `Number Serious Injuries`, `Number Non-fatal Injuries`) quantify crash outcomes and will be combined into an overall crash severity measure. Temporal and location context is provided by `DateTime`, `County`, `Area Type` (rural/urban), and `Functional Class` (e.g., local, collector, arterial, interstate).\n",
    "\n",
    "Crash circumstances are described by `Crash Manner` (e.g., rear-end, angle, single-vehicle), `Visibility Obstruction`, `Lighting Conditions`, `Roadway Curvature and Grade`, `Lane Separation`, `Number of Lanes`, and `AADT (Average Annual Daily Traffic)` as a traffic-exposure proxy. Traffic units and driver characteristics are captured through `Number of Vehicles`, `Vehicle Type`, `Driver Gender`, `Driver License Status`, `Driver Age`, `Driver BAC`, `Impact Speed`, and `Speed Limit`, which together allow exploration of behavioral and speed-related factors associated with more severe outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.1.3. Overall Observation\n",
    "The full crash dataset contains 160,163 crash-level observations and 22 variables, which matches our planned list of roadway, environmental, traffic, and driver-related fields. Six variables are stored as numeric from the start (injury counts, AADT, Driver Age, and BAC), while the remaining 16 are objects that encode dates or categorical descriptors and will need type conversion before analysis. The descriptive statistics show that most crashes have zero recorded injuries, AADT values span from a special negative code (−1) up to about 151,000, and driver age ranges from 0 to 150, indicating both plausible variation and a few values that warrant closer checking (e.g., very young/old ages and negative AADT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 2.2. Type conversion and basic tidying\n",
    "Next, we convert key columns to appropriate types and derive a few helper variables (time fields, severity index, cleaned speeds). We created a python helper file for data cleaning named `cleaning.py` to meet following objectives:\n",
    "\n",
    "1. To derive hour, weekday, and a weekend flag from `DateTime`, and create a simple `Time of Day` variable that classifies crashes as **Daytime** (06:00–17:59) or **Nighttime** (18:00–05:59). This will allow us to compare crash severity and conditions between day and night in later EDA.\n",
    "2. To coerce injury counts, driver age, BAC, and AADT to numeric. Any non-numeric entries (e.g., blanks, text codes) become `NaN` so they can be handled explicitly.\n",
    "3. To transform `Impact Speed` stored as text ranges (e.g., \"11 to 15 MPH\") or single values. We extract all numeric values in the string and, when a range is present, replace it with the midpoint (average of the two bounds); single values are kept as-is and unknown entries become missing in the numeric variable `Impact Speed Num`.\n",
    "4. To transform `Number of Vehicles` stored as text labels (e.g., \"2 Vehicles\") to numeric (2.0). Extracted the count from `Number of Vehicles`\n",
    "5. To transform `Speed Limit` stored as text labels (e.g., \"35 MPH\") to numeric (35.0). Removed the \"MPH\" suffix from `Speed Limit`\n",
    "6. To transform `Number of Lanes` stored as text labels (e.g., \"Six Lanes or More\") to numeric (6.0). Mapped lane descriptions to lane counts, treating \"Six Lanes or More\" as 6 and parking-lot/unknown values as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaning_utils as cu\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/Raw_Data.csv\")\n",
    "\n",
    "# Time variables\n",
    "df = cu.add_time_variables(df)\n",
    "\n",
    "# Coerce core numeric columns\n",
    "numeric_cols = [\n",
    "    \"Number Killed\",\n",
    "    \"Number Serious Injuries\",\n",
    "    \"Number Non-fatal Injuries\",\n",
    "    \"Driver Age\",\n",
    "    \"Driver BAC\",\n",
    "    \"AADT\",\n",
    "]\n",
    "df = cu.coerce_numeric(df, numeric_cols)\n",
    "\n",
    "# Derived numeric versions\n",
    "df[\"Impact Speed Num\"] = cu.impact_speed_to_numeric(df[\"Impact Speed\"])\n",
    "df[\"Number of Vehicles Num\"] = cu.vehicles_to_numeric(df[\"Number of Vehicles\"])\n",
    "df[\"Speed Limit Num\"] = cu.speed_limit_to_numeric(df[\"Speed Limit\"])\n",
    "df[\"Number of Lanes Num\"] = cu.lanes_to_numeric(df[\"Number of Lanes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 2.3. Creating crash severity variable\n",
    "We combine the injury count fields into an ordinal `Crash Severity` variable for use as our main outcome in later analyses. We define four mutually exclusive categories:\n",
    "\n",
    "- **PDO**: Property Damage Only: no recorded injuries.\n",
    "- **Minor**: at least one non-fatal injury, but no serious injuries or fatalities.\n",
    "- **Serious**: at least one serious injury, but no fatalities.\n",
    "- **Fatal**: at least one fatality.\n",
    "\n",
    "This ordered factor will anchor many of our subsequent EDA plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total Injuries\"] = (\n",
    "    df[\"Number Killed\"] + df[\"Number Serious Injuries\"] + df[\"Number Non-fatal Injuries\"]\n",
    ")\n",
    "\n",
    "\n",
    "# FHWA crash severity matrix\n",
    "def categorize_severity(row):\n",
    "    if row[\"Number Killed\"] > 0:\n",
    "        return \"Fatal\"\n",
    "    elif row[\"Number Serious Injuries\"] > 0:\n",
    "        return \"Serious\"\n",
    "    elif row[\"Total Injuries\"] > 0:\n",
    "        return \"Minor\"\n",
    "    else:\n",
    "        return \"PDO\"\n",
    "\n",
    "\n",
    "df[\"Crash Severity\"] = df.apply(categorize_severity, axis=1)\n",
    "\n",
    "severity_order = [\"PDO\", \"Minor\", \"Serious\", \"Fatal\"]\n",
    "df[\"Crash Severity\"] = pd.Categorical(df[\"Crash Severity\"], categories=severity_order, ordered=True)\n",
    "\n",
    "df[\"Crash Severity\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 2.4. Data quality assessment\n",
    "\n",
    "We now examine missing data, special codes (e.g., -1, \"Unknown\"), and basic ranges for numeric variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 2.4.1. Overall missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_prop = df.isna().mean().sort_values(ascending=False)\n",
    "missing_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Observation\n",
    "The table above shows the proportion of missing values in each variable. We will pay particular attention to any variables with substantial missingness (for example, driver BAC or impact speed). The missingness profile shows that most variables are fully observed, but a few have substantial gaps. `Driver BAC` is missing for about 99% of crashes, reflecting that BAC is only recorded when DUI is suspected or a test is performed, so this is structural rather than random missingness. `Impact Speed Num`, `AADT`, `Lane Separation`, `Driver Age`, `Speed Limit Num`, and `Number of Lanes Num` have moderate missingness, often due to text codes, unmeasured values, or special codes (e.g., negative AADT) that were recoded as `NaN` during cleaning. For subsequent analyses we keep all crashes, treat these missing values as “data not recorded,” and use BAC only in a focused subsample where it is available, rather than restricting the main dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 2.4.2 Fix negative/special numeric codes (e.g., AADT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of numeric columns\n",
    "df.columns\n",
    "df.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ranges for main numeric variables\n",
    "df[\n",
    "    [\n",
    "        \"Number Killed\",\n",
    "        \"Number Serious Injuries\",\n",
    "        \"Number Non-fatal Injuries\",\n",
    "        \"Driver Age\",\n",
    "        \"Driver BAC\",\n",
    "        \"Impact Speed Num\",\n",
    "        \"Speed Limit Num\",\n",
    "        \"Number of Vehicles Num\",\n",
    "        \"Number of Lanes Num\",\n",
    "        \"Total Injuries\",\n",
    "        \"AADT\",\n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Observation\n",
    "The extended numeric summary shows that crashes typically involve about 2 vehicles and 3–4 lanes, with very few cases exceeding 4 vehicles or 6 lanes. Injury counts remain zero for most crashes, but when injuries occur the total can reach up to 47 people in a single event, indicating a small number of high‑severity, multi‑party crashes. Driver age has a median of 34 years and an interquartile range of roughly 23–52 years, but spans from 0 to 150, suggesting a few implausible ages that may reflect data entry or coding issues. Posted speed limits mostly fall between 35 and 55 mph and impact speed midpoints cluster around 30 mph, while AADT again ranges from a special code (−1, treated as missing) to over 150,000, capturing both low‑volume rural roads and high‑volume urban facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode negative AADT as missing\n",
    "df.loc[df[\"AADT\"] < 0, \"AADT\"] = np.nan\n",
    "\n",
    "# Flag clearly implausible ages\n",
    "implausible_ages = (df[\"Driver Age\"] < 10) | (df[\"Driver Age\"] > 100)\n",
    "implausible_ages.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Observation\n",
    "A small number of driver ages appear implausible: 66 records have ages below 10 or above 100 years. These values likely reflect data entry or coding errors rather than true driver characteristics, we set them to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting implausible ages to NaN\n",
    "df.loc[implausible_ages, \"Driver Age\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a BAC availability flag\n",
    "df[\"BAC Available\"] = ~df[\"Driver BAC\"].isna()\n",
    "df[\"BAC Available\"].mean()  # proportion tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Observation\n",
    "Only about 1.2% of crashes have a recorded `Driver BAC`, confirming that BAC is documented primarily when DUI is suspected or a test is performed rather than for all drivers. We create a DUI subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUI subset creation\n",
    "dui_df = df[df[\"BAC Available\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 2.4.3. Recoding categorical variables\n",
    "\n",
    "To simplify interpretation and align variables with our research questions, we recoded several detailed categorical fields into cleaner, analysis-ready versions. `Functional Class Recode` collapses the original FHWA classes by merging “Principal Arterial – Other” and “Principal Arterial – Other Freeways or Expressways” into a single **Principal Arterial** category, combines **Major Collector** and **Minor Collector** into **Collector**, and treats explicit “Null value” entries as missing. For crash type, `Crash Manner Recode` groups a variety of side-impact, angle, and backing side collisions into **Sideswipe / Angle**, combines frontal oncoming configurations into **Head-On**, merges rear-end and backing rear-to-rear crashes into **Rear-End**, sets “Unknown” to missing, and classifies all remaining patterns as **Others**.\n",
    "\n",
    "Environmental and roadway context variables were also streamlined. `Visibility Obstruction Recode` distinguishes three states: **No** when not obscured, **Yes** for any specific obstruction, and missing when the unit is unknown. `Lighting Conditions Recode` aggregates many detailed lighting codes into five interpretable categories: **Daylight**, **Illuminated** (dark with spot illumination), **Night-lighted** (dark with continuous street lighting), **Dark** (roadway not lighted), and **Dusk/Dawn**, while unknown or not applicable values are set to missing and rare patterns labeled **Others**. For cross-section design, `Raised Median` is a binary indicator derived from `Lane Separation` that takes **Yes** when a physical separator (paved surface, concrete barrier, metal guardrail, or unpaved surface) is present, **No** for other markings, and missing when separation is not applicable or unknown. In addition, `Curvature` and `Grade` flags are extracted from `Roadway Curvature and Grade`, indicating whether a crash occurred on any curve (**Yes/No**) and whether vertical grade features (up/down grade, hillcrest, sag) were present.\n",
    "\n",
    "Vehicle and driver characteristics were recoded to focus on meaningful categories and reduce unknowns. `Vehicle Type Recode` retains major light-vehicle and truck types (passenger cars, SUVs, pickups, minivans, selected trucks, cargo vans, motorcycles), treats explicitly unknown/unspecified motorized vehicles as missing, and collapses all remaining rare types into **Others**. `Driver Gender Recode` keeps only **Male** and **Female**, setting all other statuses to missing. Finally, `Driver License Validity` summarizes licensing into a simple indicator: **Yes** for current/valid licenses, **No** for any clearly invalid or non-current status (e.g., suspended, revoked, expired), and missing when the status is unknown or the record does not correspond to a vehicle driver. Together, these recodes reduce sparse categories and ambiguous codes, making the dataset more interpretable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "cat_cols = [\n",
    "    \"County\",\n",
    "    \"Area Type\",\n",
    "    \"Functional Class\",\n",
    "    \"Crash Manner\",\n",
    "    \"Visibility Obstruction\",\n",
    "    \"Lighting Conditions\",\n",
    "    \"Vehicle Type\",\n",
    "    \"Driver Gender\",\n",
    "    \"Driver License Status\",\n",
    "    \"Roadway Curvature and Grade\",\n",
    "    \"Lane Separation\",\n",
    "    \"Weekend\",\n",
    "    \"Time of Day\",\n",
    "]\n",
    "\n",
    "# Investigate categorical options\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n----- {col} -----\")\n",
    "    print(df[col].value_counts(dropna=False).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECODING\n",
    "# -----------------------------\n",
    "# Functional Class recode (5 class by FHWA)\n",
    "# -----------------------------\n",
    "df[\"Functional Class Recode\"] = df[\"Functional Class\"]\n",
    "\n",
    "df[\"Functional Class Recode\"] = df[\"Functional Class Recode\"].replace(\n",
    "    {\n",
    "        \"Principal Arterial - Other\": \"Principal Arterial\",\n",
    "        \"Principal Arterial - Other Freeways or Expressways\": \"Principal Arterial\",\n",
    "        \"Major Collector\": \"Collector\",\n",
    "        \"Minor Collector\": \"Collector\",\n",
    "        \"Null value\": np.nan,\n",
    "    }\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Crash Manner recode\n",
    "# -----------------------------\n",
    "sideswipe_set = {\n",
    "    \"Sideswipe - Same Direction\",\n",
    "    \"Sideswipe - Opposite Direction\",\n",
    "    \"Side Impact (90 degrees)\",\n",
    "    \"Side Impact (angled)\",\n",
    "    \"Angle (front to side) Opposite Direction\",\n",
    "    \"Angle (front to side) Same Direction\",\n",
    "    \"Causal Veh Backing: Rear to Side\",\n",
    "}\n",
    "\n",
    "headon_set = {\"Angle Oncoming (frontal)\", \"Head-On (front to front only)\"}\n",
    "\n",
    "rear_set = {\"Rear End (front to rear)\", \"Causal Veh Backing: Rear to Rear\"}\n",
    "\n",
    "unknown_set = {\"Unknown\"}\n",
    "\n",
    "\n",
    "def recode_crash_manner(x):\n",
    "    if x in sideswipe_set:\n",
    "        return \"Sideswipe / Angle\"\n",
    "    elif x in headon_set:\n",
    "        return \"Head-On\"\n",
    "    elif x in rear_set:\n",
    "        return \"Rear-End\"\n",
    "    elif x in unknown_set:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return \"Others\"\n",
    "\n",
    "\n",
    "df[\"Crash Manner Recode\"] = df[\"Crash Manner\"].apply(recode_crash_manner)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Visibility Obstruction recode\n",
    "# -----------------------------\n",
    "def recode_visibility(x):\n",
    "    if x == \"CU is Unknown\":\n",
    "        return np.nan\n",
    "    elif x == \"Not Obscured\":\n",
    "        return \"No\"\n",
    "    else:\n",
    "        return \"Yes\"\n",
    "\n",
    "\n",
    "df[\"Visibility Obstruction Recode\"] = df[\"Visibility Obstruction\"].apply(recode_visibility)\n",
    "\n",
    "# -----------------------------\n",
    "# Lighting Conditions recode\n",
    "# -----------------------------\n",
    "illuminated = {\n",
    "    \"E Dark - Spot Illumination Both Sides of Roadway\",\n",
    "    \"E Dark - Spot Illumination One Side of Roadway\",\n",
    "}\n",
    "\n",
    "night_lighted = {\n",
    "    \"E Dark - Continuous Lighting Both Sides of Roadway\",\n",
    "    \"E Dark - Continuous Lighting One Side of Roadway\",\n",
    "    \"Dark - Roadway Lighted\",\n",
    "}\n",
    "\n",
    "\n",
    "def recode_lighting(x):\n",
    "    if x in illuminated:\n",
    "        return \"Illuminated\"\n",
    "    elif x in night_lighted:\n",
    "        return \"Night-lighted\"\n",
    "    elif x == \"Dark - Roadway Not Lighted\":\n",
    "        return \"Dark\"\n",
    "    elif x in [\"Dusk\", \"Dawn\"]:\n",
    "        return \"Dusk/Dawn\"\n",
    "    elif x in [\"Unknown\", \"E Dark - Unknown Roadway Lighting\", \"Not Applicable\"]:\n",
    "        return np.nan\n",
    "    elif x == \"Daylight\":\n",
    "        return \"Daylight\"\n",
    "    else:\n",
    "        return \"Others\"\n",
    "\n",
    "\n",
    "df[\"Lighting Conditions Recode\"] = df[\"Lighting Conditions\"].apply(recode_lighting)\n",
    "\n",
    "# -----------------------------\n",
    "# Vehicle Type recode\n",
    "# -----------------------------\n",
    "vehicle_unknown = {\"E Unknown Type of Motorized Vehicle\", \"CU is Unknown\", \"Unknown\"}\n",
    "\n",
    "vehicles = {\"Passenger Car\", \"Motorcycle\"}\n",
    "\n",
    "pickup = {\"Pick-Up (Four-Tire Light Truck)\"}\n",
    "\n",
    "suv = {\"E Sport Utility Vehicle (SUV)\", \"E 4-Wheel Off Road ATV\"}\n",
    "\n",
    "trucks = {\n",
    "    \"E Single-Unit Truck (2-Axle/6-Tire)\",\n",
    "    \"E Tractor/Semi-Trailer\",\n",
    "    \"E Single-Unit Truck (3 Axles or Less)\",\n",
    "    \"E Truck (6 or 7) with Trailer\",\n",
    "    \"E Other Heavy Truck (Cannot Classify)\",\n",
    "    \"E Truck Tractor Only (Bobtail)\",\n",
    "    \"E Tractor/Doubles\",\n",
    "    \"E Low Speed Vehicle\",\n",
    "    \"E Other Light Truck (10000 lbs or Less)\",\n",
    "}\n",
    "\n",
    "vans = {\"E Mini-van\", \"E Cargo Van (10000 lbs or Less)\", \"E Passenger Van\", \"E Van or Mini-Van\"}\n",
    "\n",
    "\n",
    "def recode_vehicle_type(x):\n",
    "    if x in vehicle_unknown:\n",
    "        return np.nan\n",
    "    elif x in vehicles:\n",
    "        return x\n",
    "    elif x in pickup:\n",
    "        return \"Pickup\"\n",
    "    elif x in vans:\n",
    "        return \"Van\"\n",
    "    elif x in trucks:\n",
    "        return \"Truck\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "\n",
    "df[\"Vehicle Type Recode\"] = df[\"Vehicle Type\"].apply(recode_vehicle_type)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Driver Gender recode\n",
    "# -----------------------------\n",
    "def recode_gender(x):\n",
    "    if x in [\"Male\", \"Female\"]:\n",
    "        return x\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df[\"Driver Gender Recode\"] = df[\"Driver Gender\"].apply(recode_gender)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Driver License Validity\n",
    "# -----------------------------\n",
    "def recode_license_validity(x):\n",
    "    if x == \"Current/Valid\":\n",
    "        return \"Yes\"\n",
    "    elif x in [\"Unknown\", \"CU is Not a Vehicle\"]:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "\n",
    "df[\"Driver License Validity\"] = df[\"Driver License Status\"].apply(recode_license_validity)\n",
    "\n",
    "# -----------------------------\n",
    "# Raised Median indicator from Lane Separation\n",
    "# -----------------------------\n",
    "raised_yes = {\"Paved Surface\", \"Concrete Barrier\", \"Metal Guard Rail\", \"Unpaved Surface\"}\n",
    "\n",
    "\n",
    "def recode_raised_median(x):\n",
    "    if x in [\"NaN\", np.nan, \"Not Applicable\", \"CU is Unknown\"]:\n",
    "        return np.nan\n",
    "    elif x in raised_yes:\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "\n",
    "df[\"Raised Median\"] = df[\"Lane Separation\"].apply(recode_raised_median)\n",
    "\n",
    "# -----------------------------\n",
    "# Curvature and Grade separation\n",
    "# -----------------------------\n",
    "curved_keywords = [\"Curve\"]\n",
    "grade_keywords = [\"Down Grade\", \"Up Grade\", \"Hillcrest\", \"Sag\"]\n",
    "\n",
    "\n",
    "def has_curvature(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    text = str(x)\n",
    "    # any curve (left/right) counts as Yes\n",
    "    return \"Yes\" if \"Curve\" in text else \"No\"\n",
    "\n",
    "\n",
    "def has_grade(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    text = str(x)\n",
    "    return \"Yes\" if any(k in text for k in grade_keywords) else \"No\"\n",
    "\n",
    "\n",
    "df[\"Curvature\"] = df[\"Roadway Curvature and Grade\"].apply(has_curvature)\n",
    "df[\"Grade\"] = df[\"Roadway Curvature and Grade\"].apply(has_grade)\n",
    "\n",
    "# Make them categorical\n",
    "df[\"Curvature\"] = df[\"Curvature\"].astype(\"category\")\n",
    "df[\"Grade\"] = df[\"Grade\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 2.5. Summarizing and saving cleaned dataset\n",
    "### 2.5.1. Creating cleaned datset\n",
    "We now create a cleaned datset including the recoded and modified columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to keep\n",
    "keep_cols = [\n",
    "    # Severity Related\n",
    "    \"Number Killed\",\n",
    "    \"Number Serious Injuries\",\n",
    "    \"Number Non-fatal Injuries\",\n",
    "    \"Total Injuries\",\n",
    "    \"Crash Severity\",\n",
    "    # time/location\n",
    "    \"Weekend\",\n",
    "    \"Time of Day\",\n",
    "    \"County\",\n",
    "    \"Area Type\",\n",
    "    # roadway / traffic\n",
    "    \"Functional Class Recode\",\n",
    "    \"AADT\",\n",
    "    \"Curvature\",\n",
    "    \"Grade\",\n",
    "    \"Raised Median\",\n",
    "    \"Number of Lanes Num\",\n",
    "    \"Number of Vehicles Num\",\n",
    "    \"Speed Limit Num\",\n",
    "    \"Impact Speed Num\",\n",
    "    # driver / vehicle\n",
    "    \"Vehicle Type Recode\",\n",
    "    \"Driver Gender Recode\",\n",
    "    \"Driver License Validity\",\n",
    "    \"Driver Age\",\n",
    "    \"Driver BAC\",\n",
    "    \"BAC Available\",\n",
    "    # environment\n",
    "    \"Crash Manner Recode\",\n",
    "    \"Visibility Obstruction Recode\",\n",
    "    \"Lighting Conditions Recode\",\n",
    "]\n",
    "\n",
    "# Create a cleaned dataframe\n",
    "cleaned_df = df[keep_cols].copy()\n",
    "\n",
    "# Convert object to category\n",
    "obj_cols = cleaned_df.select_dtypes(include=\"object\").columns\n",
    "for col in obj_cols:\n",
    "    cleaned_df[col] = cleaned_df[col].astype(\"category\")\n",
    "\n",
    "# Check\n",
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 2.5.2. Saving cleaned datset\n",
    "We save both the full working dataframe and the cleaned analysis dataset in pickle format (`crash_2018_full.pkl` and `crash_2018_cleaned.pkl`). These binary files preserve dtypes (including categorical variables) and can be loaded quickly in later notebooks for univariate, bivariate, and multivariate EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full working dataframe (with originals + recodes)\n",
    "df.to_pickle(\"../data/cleaned/crash_2018_full.pkl\")\n",
    "\n",
    "# Save cleaned analysis dataset\n",
    "cleaned_df.to_pickle(\"../data/cleaned/crash_2018_cleaned.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
